#!/bin/bash

echo "ğŸš€ Starting DocVeil Backend Server..."
echo ""

# Check if Ollama is running
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama not found. Please install Ollama first."
    exit 1
fi

# Check if llama3.1:8b model is available
if ! ollama list | grep -q "llama3.1:8b"; then
    echo "âš ï¸  llama3.1:8b model not found."
    echo "Pulling model... (this may take a while)"
    ollama pull llama3.1:8b
fi

echo "âœ… All dependencies ready!"
echo ""
echo "ğŸ“¡ Starting FastAPI server on http://localhost:8000"
echo "ğŸ“– API docs will be available at: http://localhost:8000/docs"
echo ""
echo "Press Ctrl+C to stop the server"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# Start the server
python api.py
